{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Write a short paragraph about commodities:\n",
      "\n",
      "Generated Response:\n",
      "Write a short paragraph about commodities:\n",
      "\n",
      "Commodities are essential for human survival. They are the raw materials that are used to produce goods and services. Commodities are produced in large quantities and are traded on the global market. They are essential for the development of economies and the well-being of people. Commodities are essential for the production of goods and services, such as food, clothing, and housing. They are also essential for the\n"
     ]
    }
   ],
   "source": [
    "# Packages \n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Set the path to the directory containing the model files\n",
    "model_path = \"D:\\Data\\OneDrive\\Ccantu\\OneDrive - CFTC\\Documents\\Python Scripts\\TinyLlama\" # Replace with correct path \n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "\n",
    "def generate_response(prompt, max_length=100): # max_length keeps response short \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(**inputs, max_length=max_length, num_return_sequences=1) # num_return_sequences gives only 1 output sequence \n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True) # Turns output into a readable text and skips padding to a length \n",
    "\n",
    "# Example prompt case \n",
    "prompt = \"Write a short paragraph about commodities:\"\n",
    "response = generate_response(prompt)\n",
    "print(f\"Prompt: {prompt}\\n\")\n",
    "print(f\"Generated Response:\\n{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tron_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
